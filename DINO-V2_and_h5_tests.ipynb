{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cdca41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'tiger, Panthera tigris', 'score': 0.24335609376430511},\n",
       " {'label': 'tiger cat', 'score': 0.24146227538585663},\n",
       " {'label': 'lynx, catamount', 'score': 0.16084855794906616},\n",
       " {'label': 'marmot', 'score': 0.043973542749881744},\n",
       " {'label': 'tabby, tabby cat', 'score': 0.03293466567993164}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HF Example\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"image-classification\",\n",
    "    model=\"facebook/dinov2-small-imagenet1k-1-layer\",\n",
    "    dtype=torch.float16,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "pipe(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c8def47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "cls_embedding = last_hidden_states[:, 0, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc1c43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(cls_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90459edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95240444  1.3240675   0.28314427 ... -0.40695077 -0.12938523\n",
      "   0.65251255]\n",
      " [ 0.73756576  1.2255933   0.01971832 ... -2.2677386   0.3768237\n",
      "   1.4319218 ]\n",
      " [ 0.8730782   1.568318    0.21059269 ...  1.7526027  -1.3327127\n",
      "   1.7590166 ]\n",
      " ...\n",
      " [ 2.8841746  -2.7090735  -1.8563217  ...  3.5333478  -1.8200037\n",
      "  -1.7979321 ]\n",
      " [ 0.7231116  -0.3009514  -2.2173426  ... -2.9620824   1.0859857\n",
      "   0.02212841]\n",
      " [ 0.88997984  0.62839216 -1.7182935  ... -2.0426896   2.6787934\n",
      "   1.5962486 ]]\n",
      "[[38.01888  -7.86417 ]\n",
      " [42.89792  -5.537902]\n",
      " [43.729904  3.313452]\n",
      " ...\n",
      " [47.63359  12.09996 ]\n",
      " [48.365     6.681111]\n",
      " [50.73414   9.120029]]\n"
     ]
    }
   ],
   "source": [
    "import hdf5\n",
    "file=hdf5.open_HDF5(\"downloaded_embeddings.h5\")\n",
    "vectors=file[\"vectors\"]\n",
    "vectors=vectors[:] #load into a np array\n",
    "labels=file[\"coordinates\"]\n",
    "labels=labels[:]\n",
    "print(vectors)\n",
    "print(labels)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae0b9a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agah\n",
      "coordinates: shape=(3167055, 2), dtype=float32\n",
      "vectors: shape=(3167055, 768), dtype=float32\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import hdf5\n",
    "#Size of hp5\n",
    "print(\"agah\")\n",
    "path=\"/home/adam/source/CLIP/full_dataset_embeddings.h5\"\n",
    "hdf5.get_size(path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c75a71cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarities: 100%|██████████| 50/50 [00:00<00:00, 539.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Std: tensor(0.0655, device='cuda:0', grad_fn=<SqrtBackward0>) tensor(0.0752, device='cuda:0', grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test the clip model\n",
    "\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "importlib.reload(utils)\n",
    "from tqdm import tqdm\n",
    "\n",
    "#for having the right model; print the model if unsurea about the layers\n",
    "dim_fourier_encoding=64 #multiple of 4!!\n",
    "dim_hidden=256\n",
    "dim_emb=128 #this one is actually shared with img embeddings\n",
    "device=\"cuda\"\n",
    "data_path=\"/home/adam/source/CLIP/full_dataset_embeddings.h5\"\n",
    "#dim image layer size: \n",
    "#As of now: linear from 768 to dim_emb. We could also have MLP if non-linearity needed\n",
    "\n",
    "image_encoder=nn.Linear(768,dim_emb).to(device)\n",
    "pos_encoder=utils.Fourier_MLP(original_dim=2, fourier_dim=dim_fourier_encoding, hidden_dim=dim_hidden, output_dim=dim_emb).to(device)\n",
    "\n",
    "model= utils.DoubleNetwork(image_encoder,pos_encoder).to(device)\n",
    "model.load_state_dict(torch.load(\"/home/adam/source/CLIP/save_14_to_17-10-25/model.pt\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "nbr_iter=50\n",
    "mean_sim, mean_asim, std_sim, std_asim = utils.test_similarity(data_path,model, nbr_samples=2,device=\"cuda\",nbr_iter=nbr_iter,plot_sims=True)\n",
    "print(\"Mean:\", mean_sim, mean_asim)\n",
    "print(\"Std:\", std_sim, std_asim)\n",
    "#for the whole test  set:\n",
    "#Mean: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n",
    "#Std: tensor(0.0645, device='cuda:0', grad_fn=<SqrtBackward0>) tensor(0.0726, device='cuda:0', grad_fn=<SqrtBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5215ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gbifID', 'accessRights', 'bibliographicCitation', 'language',\n",
      "       'license', 'modified', 'publisher', 'references', 'rightsHolder',\n",
      "       'type',\n",
      "       ...\n",
      "       'publishedByGbifRegion', 'level0Gid', 'level0Name', 'level1Gid',\n",
      "       'level1Name', 'level2Gid', 'level2Name', 'level3Gid', 'level3Name',\n",
      "       'iucnRedListCategory'],\n",
      "      dtype='object', length=226)\n",
      "Number of datapoints in Switzerland: 74963\n",
      "Number of datapoints in France: 884128\n"
     ]
    }
   ],
   "source": [
    "#Number of occurences in Switwerland\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Replace 'data.tsv' with the path to your file\n",
    "file_path = '/home/adam/source/CLIP/data_plantnet_obsevations/occurrence.txt'\n",
    "\n",
    "# Load the TSV file\n",
    "df = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "# Check the column names for country info\n",
    "print(df.columns)\n",
    "\n",
    "# Filter rows where the country is Switzerland\n",
    "switzerland_data = df[df['countryCode'] == 'CH']\n",
    "\n",
    "# Count the number of rows\n",
    "num_datapoints = len(switzerland_data)\n",
    "\n",
    "print(f\"Number of datapoints in Switzerland: {num_datapoints}\")\n",
    "\n",
    "# Filter rows where the country is Switzerland\n",
    "france_data = df[df['countryCode'] == 'FR']\n",
    "\n",
    "# Count the number of rows\n",
    "num_datapoints = len(france_data)\n",
    "\n",
    "print(f\"Number of datapoints in France: {num_datapoints}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1855059",
   "metadata": {},
   "source": [
    "densité de points en suisse: \n",
    "74963/41 285 km2=1.81\n",
    "\n",
    "France: 884128/632 702 km2=1.39\n",
    "We good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aa06de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countryCode\n",
      "FR    884128\n",
      "ES    253748\n",
      "DE    237009\n",
      "IT    199536\n",
      "GB    132793\n",
      "US    125428\n",
      "NL    104618\n",
      "CH     74963\n",
      "CZ     61113\n",
      "BE     59173\n",
      "AT     44565\n",
      "PL     36438\n",
      "CA     29717\n",
      "PT     28453\n",
      "RU     22644\n",
      "HU     21479\n",
      "SK     16528\n",
      "BR     15615\n",
      "GR     14699\n",
      "KE     14308\n",
      "SE     13236\n",
      "HR     11800\n",
      "TR     11083\n",
      "IN     11004\n",
      "IE      9793\n",
      "DK      9445\n",
      "NO      9042\n",
      "UA      8886\n",
      "RO      8085\n",
      "FI      8053\n",
      "SI      7181\n",
      "RE      6587\n",
      "AR      6290\n",
      "AU      4955\n",
      "BG      4680\n",
      "CL      3733\n",
      "MX      3678\n",
      "RS      3487\n",
      "CR      3089\n",
      "MA      3013\n",
      "DZ      2681\n",
      "CO      2623\n",
      "GP      2530\n",
      "LU      2396\n",
      "ZA      2232\n",
      "EE      2055\n",
      "MQ      1981\n",
      "BA      1895\n",
      "ID      1850\n",
      "JP      1669\n",
      "IL      1645\n",
      "IR      1634\n",
      "BY      1602\n",
      "ME      1554\n",
      "LV      1549\n",
      "LT      1506\n",
      "NC      1490\n",
      "IS      1312\n",
      "TH      1302\n",
      "MG      1248\n",
      "CG      1143\n",
      "NZ      1088\n",
      "CY      1075\n",
      "GE       996\n",
      "MT       969\n",
      "DO       946\n",
      "AL       825\n",
      "PE       783\n",
      "GF       741\n",
      "UY       719\n",
      "MY       712\n",
      "VN       676\n",
      "AD       672\n",
      "CN       668\n",
      "TN       656\n",
      "EC       651\n",
      "PH       624\n",
      "PA       589\n",
      "PR       537\n",
      "VE       499\n",
      "NG       494\n",
      "MU       486\n",
      "TZ       486\n",
      "PF       484\n",
      "PK       445\n",
      "GT       421\n",
      "GG       394\n",
      "MK       385\n",
      "SG       372\n",
      "BO       371\n",
      "LK       367\n",
      "CM       359\n",
      "MD       344\n",
      "AM       319\n",
      "CU       312\n",
      "NP       304\n",
      "JE       300\n",
      "SN       291\n",
      "KZ       286\n",
      "LB       282\n",
      "HN       262\n",
      "CD       253\n",
      "KR       227\n",
      "KH       217\n",
      "SV       207\n",
      "TW       206\n",
      "AZ       204\n",
      "CI       204\n",
      "BD       196\n",
      "LI       190\n",
      "GH       182\n",
      "EG       177\n",
      "ET       174\n",
      "JM       173\n",
      "SY       172\n",
      "UG       170\n",
      "LA       170\n",
      "SA       163\n",
      "OM       161\n",
      "CV       160\n",
      "BJ       142\n",
      "MZ       138\n",
      "UZ       137\n",
      "BL       137\n",
      "NI       137\n",
      "HK       132\n",
      "JO       117\n",
      "PY       115\n",
      "SC       112\n",
      "TT       112\n",
      "KG       109\n",
      "PS        99\n",
      "AX        97\n",
      "GN        97\n",
      "BZ        90\n",
      "BT        89\n",
      "SR        87\n",
      "AE        86\n",
      "BF        84\n",
      "IM        84\n",
      "MS        81\n",
      "GM        81\n",
      "BB        80\n",
      "MF        79\n",
      "XK        78\n",
      "GI        78\n",
      "SM        77\n",
      "VI        77\n",
      "MC        74\n",
      "ST        68\n",
      "RW        68\n",
      "LC        68\n",
      "ZW        64\n",
      "ZM        63\n",
      "PM        61\n",
      "FO        60\n",
      "GA        59\n",
      "YT        58\n",
      "TG        58\n",
      "MV        53\n",
      "BQ        52\n",
      "DM        52\n",
      "WF        51\n",
      "TD        51\n",
      "IQ        51\n",
      "CW        50\n",
      "MM        49\n",
      "LY        48\n",
      "BS        42\n",
      "MR        37\n",
      "HT        36\n",
      "ML        35\n",
      "PG        32\n",
      "MW        28\n",
      "WS        28\n",
      "CK        24\n",
      "BM        23\n",
      "FJ        22\n",
      "GL        22\n",
      "AG        22\n",
      "BN        21\n",
      "MN        20\n",
      "VC        20\n",
      "TC        19\n",
      "GW        19\n",
      "VG        19\n",
      "AO        17\n",
      "BW        17\n",
      "YE        17\n",
      "AW        17\n",
      "KM        17\n",
      "KY        17\n",
      "SD        16\n",
      "GY        16\n",
      "GD        16\n",
      "SJ        15\n",
      "TL        15\n",
      "SX        14\n",
      "VU        13\n",
      "DJ        13\n",
      "SZ        13\n",
      "SS        12\n",
      "CF        12\n",
      "NE        11\n",
      "TJ         9\n",
      "VA         9\n",
      "KN         9\n",
      "SL         8\n",
      "TO         8\n",
      "AI         7\n",
      "MP         6\n",
      "KP         5\n",
      "KW         5\n",
      "SH         4\n",
      "EH         4\n",
      "QA         4\n",
      "GU         4\n",
      "BI         3\n",
      "AF         3\n",
      "MO         2\n",
      "LS         2\n",
      "LR         2\n",
      "BH         2\n",
      "PW         1\n",
      "SB         1\n",
      "ER         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace 'data.tsv' with the path to your file\n",
    "file_path =  '/home/adam/source/CLIP/data_plantnet_obsevations/occurrence.txt'\n",
    "\n",
    "# Load the TSV file\n",
    "df = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "# Count datapoints per country\n",
    "country_counts = df['countryCode'].value_counts()\n",
    "\n",
    "# Display results\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Avoid line wrapping\n",
    "pd.set_option('display.max_colwidth', None)  # Full column width\n",
    "print(country_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c6b4ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoubleNetwork(\n",
       "  (image_encoder): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (pos_encoder): Fourier_MLP(\n",
       "    (MLP): CustomMLP(\n",
       "      (lin1): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (relu1): ReLU()\n",
       "      (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (relu2): ReLU()\n",
       "      (lin3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the Model\n",
    "import utils\n",
    "import importlib\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "importlib.reload(utils)\n",
    "from tqdm import tqdm\n",
    "dim_fourier_encoding=64 #multiple of 4!!\n",
    "dim_hidden=256\n",
    "dim_emb=128 #this one is actually shared with img embeddings\n",
    "device=\"cuda\"\n",
    "data_path=\"/home/adam/source/CLIP/full_dataset_embeddings.h5\"\n",
    "#dim image layer size: \n",
    "#As of now: linear from 768 to dim_emb. We could also have MLP if non-linearity needed\n",
    "\n",
    "image_encoder=nn.Linear(768,dim_emb).to(device)\n",
    "pos_encoder=utils.Fourier_MLP(original_dim=2, fourier_dim=dim_fourier_encoding, hidden_dim=dim_hidden, output_dim=dim_emb).to(device)\n",
    "\n",
    "model= utils.DoubleNetwork(image_encoder,pos_encoder).to(device)\n",
    "model.load_state_dict(torch.load(\"/home/adam/source/CLIP/save_14_to_17-10-25/model.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f306f4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting embeddings\n",
      "shape Xemb (35105, 128)\n",
      "shape Xcov (35105, 13)\n",
      "shape y (35105, 30)\n",
      "fitting models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 29.22it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      " 30%|███       | 9/30 [00:00<00:00, 69.74it/s]/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      " 70%|███████   | 21/30 [00:00<00:00, 92.05it/s]/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/home/adam/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:286: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\n",
      "100%|██████████| 30/30 [00:00<00:00, 67.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False, False,  True],\n",
       "       [False, False, False, ..., False, False,  True]], shape=(35105, 30))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model\n",
    "\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import importlib\n",
    "import torch\n",
    "importlib.reload(utils)\n",
    "\n",
    "pd.set_option('display.max_columns', None)   # show all columns\n",
    "pd.set_option('display.width', None)         # don't wrap lines\n",
    "pd.set_option('display.max_colwidth', None)  # show full column content if needed\n",
    "#np.set_printoptions(threshold=np.inf)      # print entire array, no truncation\n",
    "#np.set_printoptions(linewidth=np.inf)     \n",
    "\n",
    "\n",
    "po_data=pd.read_csv(\"data_SDM_NCEAS/SWItrain_po.csv\")\n",
    "\n",
    "y = pd.get_dummies(po_data[\"spid\"])\n",
    "po_data = pd.concat([po_data.drop(columns=[\"spid\"]), y], axis=1) #For the full one-hot-encoded dataframe\n",
    "\n",
    "po_covariates=po_data.loc[:, [\"bcc\",\"calc\",\"ccc\",\"ddeg\",\"nutri\",\"pday\",\"precyy\",\"sfroyy\",\"slope\",\"sradyy\",\"swb\",\"tavecc\",\"topo\"]]\n",
    "\n",
    "X_cov=po_covariates.to_numpy()\n",
    "y=y.to_numpy()\n",
    "\n",
    "def fit_multi_GLM(X,y):\n",
    "    PR_list=[]\n",
    "    for i in tqdm(range(y.shape[1])):\n",
    "        PR=PoissonRegressor()\n",
    "        PR.fit(X,y[:,i])\n",
    "        PR_list.append(PR)\n",
    "    return PR_list\n",
    "\n",
    "\n",
    "from pyproj import Transformer\n",
    "\n",
    "transformer_CH_to_WGS = Transformer.from_crs(\n",
    "    \"EPSG:21781\", \"EPSG:4326\", always_xy=True\n",
    ")\n",
    "\n",
    "def get_embeddings(df, pos_encoder, device=\"cuda\"):\n",
    "    # Vectorized coordinate conversion\n",
    "    \n",
    "    shift_x, shift_y= (1011627.4909483634, -100326.1477937577) #See \"coordinates.ipynb\"\n",
    "    lons, lats = utils.coord_trans(df[\"x\"].values-shift_x, df[\"y\"].values-shift_y,order=\"CH_to_normal\")\n",
    "    coords = torch.tensor(\n",
    "        np.column_stack([lats, lons]),\n",
    "        dtype=torch.float32\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = pos_encoder(coords).cpu().numpy()\n",
    "\n",
    "    return emb\n",
    "\n",
    "\n",
    "\n",
    "print(\"getting embeddings\")\n",
    "X_emb=get_embeddings(po_data, model.pos_encoder)\n",
    "print(\"shape Xemb\", X_emb.shape)\n",
    "print(\"shape Xcov\", X_cov.shape)\n",
    "print(\"shape y\",y.shape)\n",
    "#Fit GLM\n",
    "print(\"fitting models\")\n",
    "\n",
    "PR_emb=fit_multi_GLM(X_emb,y)\n",
    "PR_cov=fit_multi_GLM(X_cov,y)\n",
    "\n",
    "\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "063f8d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10013, 30)\n",
      "(10013, 30) (10013, 30)\n",
      "MSE cov: 0.06269452875856757\n",
      "MSE emb: 0.06673212654110257\n"
     ]
    }
   ],
   "source": [
    "#PA data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pa_data=pd.read_csv(\"data_SDM_NCEAS/SWItest_pa.csv\")\n",
    "env=pd.read_csv(\"data_SDM_NCEAS/SWItest_env.csv\")\n",
    "\n",
    "\n",
    "y_true = pa_data.loc[:, [\n",
    "    'swi01','swi02','swi03','swi04','swi05','swi06','swi07','swi08','swi09','swi10',\n",
    "    'swi11','swi12','swi13','swi14','swi15','swi16','swi17','swi18','swi19','swi20',\n",
    "    'swi21','swi22','swi23','swi24','swi25','swi26','swi27','swi28','swi29','swi30'\n",
    "]]\n",
    "X_test_cov = env.loc[:, [\n",
    "    'bcc', 'calc', 'ccc', 'ddeg', 'nutri', 'pday', 'precyy',\n",
    "    'sfroyy', 'slope', 'sradyy', 'swb', 'tavecc', 'topo'\n",
    "]]\n",
    "X_test_cov=X_test_cov.to_numpy()\n",
    "y_true=y_true.to_numpy()\n",
    "X_test_emb=get_embeddings(env,model.pos_encoder)\n",
    "#print(X_test_emb.shape, X_test_emb)\n",
    "\n",
    "\n",
    "output_shape=y_true.shape\n",
    "print(output_shape)\n",
    "y_pred_cov=np.zeros(output_shape)\n",
    "y_pred_emb=np.zeros(output_shape)\n",
    "for i in range(output_shape[1]):\n",
    "    y_pred_cov[:,i]=PR_cov[i].predict(X_test_cov)\n",
    "    y_pred_emb[:,i]=PR_emb[i].predict(X_test_emb)\n",
    "\n",
    "print(y_true.shape, y_pred_cov.shape)\n",
    "mse_cov = mean_squared_error(y_true, y_pred_cov)\n",
    "print(\"MSE cov:\", mse_cov)\n",
    "mse_emb = mean_squared_error(y_true, y_pred_emb)\n",
    "print(\"MSE emb:\", mse_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7b3fc1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10013, 35105]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_features):\n\u001b[32m     12\u001b[39m     PR_rand = PoissonRegressor()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mPR_rand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_rand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     y_pred_rand[:,i] = PR_rand.predict(X_rand)\n\u001b[32m     16\u001b[39m mse_rand = mean_squared_error(y_true, y_pred_rand)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/linear_model/_glm/glm.py:191\u001b[39m, in \u001b[36m_GeneralizedLinearRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    173\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit a Generalized Linear Model.\u001b[39;00m\n\u001b[32m    174\u001b[39m \n\u001b[32m    175\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    189\u001b[39m \u001b[33;03m        Fitted model.\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;66;03m# required by losses\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.solver == \u001b[33m\"\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# lbfgs will force coef and therefore raw_prediction to be float64. The\u001b[39;00m\n\u001b[32m    204\u001b[39m         \u001b[38;5;66;03m# base_loss needs y, X @ coef and sample_weight all of same dtype\u001b[39;00m\n\u001b[32m    205\u001b[39m         \u001b[38;5;66;03m# (and contiguous).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/utils/validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/utils/validation.py:1387\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1368\u001b[39m X = check_array(\n\u001b[32m   1369\u001b[39m     X,\n\u001b[32m   1370\u001b[39m     accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1382\u001b[39m     input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1383\u001b[39m )\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/CLIP/lib/python3.13/site-packages/sklearn/utils/validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [10013, 35105]"
     ]
    }
   ],
   "source": [
    "# Suppose X_train is random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Random features\n",
    "X_rand = np.random.randn(10013, 13)  # same shape as your env\n",
    "\n",
    "n_features = y.shape[1]\n",
    "y_pred_rand = np.zeros_like(y_true)\n",
    "\n",
    "for i in range(n_features):\n",
    "    PR_rand = PoissonRegressor()\n",
    "    PR_rand.fit(X_rand, y[:,i])\n",
    "    y_pred_rand[:,i] = PR_rand.predict(X_rand)\n",
    "\n",
    "mse_rand = mean_squared_error(y_true, y_pred_rand)\n",
    "print(\"MSE random:\", mse_rand)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
